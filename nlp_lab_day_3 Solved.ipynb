{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhE_ve2CMku1"
      },
      "source": [
        "\n",
        "<br>\n",
        "RNN Practical — Intro to Recurrent Neural Networks<br>\n",
        "Topics: Motivation, Basics, Architectures (One-to-Many, Many-to-One, etc.), Shared Parameters<br>\n",
        "Instructions: Complete each task by filling in the \"Your answer here\" sections.<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Eut5NBEdMku6"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzWjX89mMku-"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 1: RNN Architectures <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xlDX2hiTMku-"
      },
      "outputs": [],
      "source": [
        "def task1_architectures():\n",
        "    \"\"\"\n",
        "    Identify the correct RNN architecture (One-to-One, One-to-Many, Many-to-One, Many-to-Many)\n",
        "    for the following scenarios:\n",
        "    a) Sentiment analysis of a sentence -> single label\n",
        "    b) Music generation from a single start token -> output sequence\n",
        "    c) Named entity recognition: tag each word in a sentence\n",
        "    d) Machine translation: source sentence -> target sentence\n",
        "    \"\"\"\n",
        "    # Your answer here:\n",
        "    # a) Many-to-One\n",
        "    # b) One-to-Many\n",
        "    # c) Many-to-Many\n",
        "    # d) Many-to-Many (encoder-decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz1xbYovMkvA"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 2: Shared Parameters <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5UlHXaMJMkvB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24\n"
          ]
        }
      ],
      "source": [
        "def task2_shared_parameters():\n",
        "    \"\"\"\n",
        "    Explain shared parameters in an RNN.\n",
        "    Compute parameter counts for an example:\n",
        "      input size d=4, hidden size h=3, sequence length T=10\n",
        "    \"\"\"\n",
        "    # Your answer here:\n",
        "    d = 4  # input size\n",
        "    h = 3  # hidden size\n",
        "    # Weights from input to hidden: d * h\n",
        "    W_xh = d * h\n",
        "    # Weights from hidden to hidden: h * h\n",
        "    W_hh = h * h\n",
        "    # Biases for hidden layer: h\n",
        "    b_h = h\n",
        "    total_params = W_xh + W_hh + b_h\n",
        "    return total_params  # 12 + 9 + 3 = 24\n",
        "print(task2_shared_parameters())  # Should print 24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMyzZbkLMkvB"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 3: Manual Forward Pass <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nlcGh9oLMkvC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([ 0.46211716, -0.33637554]), array([0.53994993, 0.04027965]), array([-0.21833125,  0.19743869])]\n"
          ]
        }
      ],
      "source": [
        "def task3_manual_forward_pass():\n",
        "    \"\"\"\n",
        "    Compute hidden states manually for a small RNN using np.tanh.\n",
        "    Input sequence length T=3, input size=3, hidden size=2\n",
        "    \"\"\"\n",
        "    x_seq = [np.array([0.5, -1.0]), # this is seq of 3 inputs\n",
        "             np.array([1.0, 0.0]),\n",
        "             np.array([-0.5, 0.5])]\n",
        "    h_prev = np.zeros(2) # initial hidden state with 0 and size 2\n",
        "    W_xh = np.array([[0.6, -0.2], # weights from input to hidden\n",
        "                     [0.1,  0.5]])\n",
        "    W_hh = np.array([[0.3, 0.4], \n",
        "                     [-0.2, 0.2]])\n",
        "    b_h = np.array([0.0,0.1])\n",
        "    h_list = []\n",
        "\n",
        "    # Your code here\n",
        "    for x in x_seq:\n",
        "        h_next = np.tanh(np.dot(W_xh, x) + np.dot(W_hh, h_prev) + b_h) # compute next hidden state\n",
        "        h_list.append(h_next) # store it\n",
        "        h_prev = h_next # update previous hidden state\n",
        "    return h_list\n",
        "print(task3_manual_forward_pass()) # Done By Renad , Samar and Dona not by AI "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ORsqt1mMkvC"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 4: NumPy RNN Cell Implementation <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lSsfHVNCMkvD"
      },
      "outputs": [],
      "source": [
        "def task4_numpy_rnn_cell():\n",
        "    \"\"\"\n",
        "    Implement a simple Many-to-One RNN in NumPy.\n",
        "    Use rnn_forward to compute h_T, then compute a readout: y = W_hy h_T + b_y\n",
        "    Predict class = argmax(y)\n",
        "    \"\"\"\n",
        "\n",
        "    # Toy dataset\n",
        "    toy_sequences = [\n",
        "        [np.array([1.0,0.5]), np.array([0.2,0.1]), np.array([0.3,-0.1])],\n",
        "        [np.array([-0.5,-0.4]), np.array([0.1,-0.2]), np.array([-0.3,-0.1])],\n",
        "        [np.array([0.8,0.2]), np.array([0.5,0.4]), np.array([0.1,0.2])],\n",
        "        [np.array([-0.6,-0.2]), np.array([-0.4,-0.3]), np.array([0.0,-0.1])]\n",
        "    ]\n",
        "    labels = np.array([1,0,1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Nxyi_7bfR1vi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNNClassifier(\n",
            "  (rnn): RNN(1, 8, batch_first=True)\n",
            "  (fc): Linear(in_features=8, out_features=2, bias=True)\n",
            ")\n",
            "Epoch [10/50] Loss: 0.6571 Acc: 0.54\n",
            "Epoch [20/50] Loss: 0.5591 Acc: 0.97\n",
            "Epoch [30/50] Loss: 0.3054 Acc: 1.00\n",
            "Epoch [40/50] Loss: 0.1130 Acc: 0.96\n",
            "Epoch [50/50] Loss: 0.0642 Acc: 0.99\n",
            "\n",
            "Predictions vs Actual:\n",
            "Seq: [0.8174512982368469, 0.49319136142730713, 0.4033474922180176, 0.24551081657409668] -> Pred: 0 | Actual: 0\n",
            "Seq: [0.5612156391143799, 0.6108258962631226, 0.7026264071464539, 0.9758620262145996] -> Pred: 1 | Actual: 1\n",
            "Seq: [0.9195457100868225, 0.7085305452346802, 0.6176550388336182, 0.32304489612579346] -> Pred: 0 | Actual: 0\n",
            "Seq: [0.6818788647651672, 0.4330689311027527, 0.3951728343963623, 0.33381950855255127] -> Pred: 0 | Actual: 0\n",
            "Seq: [0.2629486322402954, 0.35671699047088623, 0.506699800491333, 0.6426212191581726] -> Pred: 1 | Actual: 1\n",
            "Seq: [0.36274904012680054, 0.4146166443824768, 0.958614706993103, 0.9708342552185059] -> Pred: 1 | Actual: 1\n",
            "Seq: [0.9602108597755432, 0.8622366189956665, 0.8593432307243347, 0.19912081956863403] -> Pred: 0 | Actual: 0\n",
            "Seq: [0.4071228504180908, 0.6238425970077515, 0.7466362714767456, 0.7907636165618896] -> Pred: 1 | Actual: 1\n",
            "Seq: [0.14515268802642822, 0.3925434947013855, 0.5312566161155701, 0.7814489603042603] -> Pred: 1 | Actual: 1\n",
            "Seq: [0.17640316486358643, 0.8262456655502319, 0.838903546333313, 0.8578501343727112] -> Pred: 1 | Actual: 1\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Goal:\n",
        "- Introduction to tensors in PyTorch\n",
        "- Build a simple RNN-based classifier\n",
        "\n",
        "Dataset:\n",
        "- We will classify short sequences of numbers as \"increasing\" or \"decreasing\"\n",
        "  Example:\n",
        "    [1, 2, 3, 4] → Label: 1 (increasing)\n",
        "    [5, 3, 1, 0] → Label: 0 (decreasing)\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ====================================================\n",
        "# STEP 1: Create a Tiny Synthetic Dataset\n",
        "# ====================================================\n",
        "\n",
        "def generate_data(num_samples=100, seq_len=4):\n",
        "    X, y = [], []\n",
        "    for _ in range(num_samples):\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            seq = torch.sort(torch.rand(seq_len))[0]   # Increasing\n",
        "            label = 1\n",
        "        else:\n",
        "            seq = torch.sort(torch.rand(seq_len), descending=True)[0]  # Decreasing\n",
        "            label = 0\n",
        "        X.append(seq.unsqueeze(-1))  # (seq_len, input_size=1)\n",
        "        y.append(label)\n",
        "    return torch.stack(X), torch.tensor(y)\n",
        "\n",
        "X, y = generate_data()\n",
        "# X shape: (batch_size=100, seq_len=4, input_size=1)\n",
        "# y shape: (batch_size=100)\n",
        "\n",
        "# ====================================================\n",
        "# STEP 2: Define a Simple RNN Classifier\n",
        "# ====================================================\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=8, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len, input_size)\n",
        "        out, h = self.rnn(x)         # out: (batch, seq_len, hidden), h: (1, batch, hidden)\n",
        "        last_hidden = h.squeeze(0)   # (batch, hidden_size)\n",
        "        logits = self.fc(last_hidden) # (batch, num_classes)\n",
        "        return logits\n",
        "\n",
        "model = RNNClassifier()\n",
        "print(model)\n",
        "\n",
        "# ====================================================\n",
        "# STEP 3: Train the Model\n",
        "# ====================================================\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    logits = model(X)\n",
        "    loss = criterion(logits, y)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch+1) % 10 == 0:\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "        acc = (pred == y).float().mean().item()\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {loss.item():.4f} Acc: {acc:.2f}\")\n",
        "\n",
        "# ====================================================\n",
        "# STEP 4: Test the Model on New Data\n",
        "# ====================================================\n",
        "\n",
        "test_X, test_y = generate_data(num_samples=10)\n",
        "with torch.no_grad():\n",
        "    test_logits = model(test_X)\n",
        "    preds = torch.argmax(test_logits, dim=1)\n",
        "\n",
        "print(\"\\nPredictions vs Actual:\")\n",
        "for i in range(len(test_X)):\n",
        "    print(f\"Seq: {test_X[i].squeeze().tolist()} -> Pred: {preds[i].item()} | Actual: {test_y[i].item()}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
